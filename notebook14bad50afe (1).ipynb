{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11848,"databundleVersionId":862157,"sourceType":"competition"}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Problem and data overview\n\nTask: Identify metastatic cancer in small pathology image patches. This is a binary image classification problem where `label = 1` indicates tumor and `label = 0` indicates normal tissue.\n\nData layout\n- `train_labels.csv` with columns `id` and `label`\n- `train/` directory of training tiles named `<id>.tif`\n- `test/` directory of test tiles named `<id>.tif`\n\nEach image is a small RGB square patch extracted from whole slide images. We will examine class balance, sample tiles, and any data issues before modeling.\n","metadata":{}},{"cell_type":"code","source":"\nimport os\nimport math\nimport random\nimport time\nimport gc\nfrom pathlib import Path\nfrom dataclasses import dataclass, asdict\n\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nfrom torchvision import models, transforms\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\n\nSEED = 42\ndef set_seed(seed=SEED):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nset_seed()\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"Device:\", DEVICE)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-22T18:02:29.971978Z","iopub.execute_input":"2025-10-22T18:02:29.972232Z","iopub.status.idle":"2025-10-22T18:02:36.911744Z","shell.execute_reply.started":"2025-10-22T18:02:29.972212Z","shell.execute_reply":"2025-10-22T18:02:36.910863Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Try to autodetect Kaggle input path. Fallback to a relative path.\nDEFAULT_KAGGLE_DIR = Path(\"/kaggle/input/histopathologic-cancer-detection\")\nLOCAL_DIR = Path(\"../input/histopathologic-cancer-detection\")\n\nif DEFAULT_KAGGLE_DIR.exists():\n    DATA_DIR = DEFAULT_KAGGLE_DIR\nelif LOCAL_DIR.exists():\n    DATA_DIR = LOCAL_DIR\nelse:\n    # Edit this path if running elsewhere\n    DATA_DIR = Path(\"./histopathologic-cancer-detection\")\n\nTRAIN_DIR = DATA_DIR / \"train\"\nTEST_DIR  = DATA_DIR / \"test\"\nLABELS_CSV = DATA_DIR / \"train_labels.csv\"\n\nprint(\"DATA_DIR:\", DATA_DIR)\nprint(\"TRAIN_DIR:\", TRAIN_DIR.exists(), \"TEST_DIR:\", TEST_DIR.exists(), \"LABELS_CSV:\", LABELS_CSV.exists())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T18:02:36.913256Z","iopub.execute_input":"2025-10-22T18:02:36.913764Z","iopub.status.idle":"2025-10-22T18:02:36.920700Z","shell.execute_reply.started":"2025-10-22T18:02:36.913744Z","shell.execute_reply":"2025-10-22T18:02:36.920096Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n@dataclass\nclass Config:\n    image_size: int = 128              # ResNet can take 128x128\n    batch_size: int = 256\n    epochs: int = 2\n    lr: float = 3e-4\n    weight_decay: float = 1e-4\n    num_workers: int = 2\n    folds: int = 5\n    train_fold: int = 0                # which fold to train in this run\n    patience: int = 2                  # early stopping patience\n    t_max: int = 6                     # CosineAnnealingLR T_max\n    model_name: str = \"resnet18\"\n    save_dir: str = \"./checkpoints\"\n    mixed_precision: bool = True\n\nCFG = Config()\nos.makedirs(CFG.save_dir, exist_ok=True)\nprint(asdict(CFG))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T18:02:36.921336Z","iopub.execute_input":"2025-10-22T18:02:36.921570Z","iopub.status.idle":"2025-10-22T18:02:36.936764Z","shell.execute_reply.started":"2025-10-22T18:02:36.921549Z","shell.execute_reply":"2025-10-22T18:02:36.936214Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nclass HistoDataset(Dataset):\n    def __init__(self, df, img_dir, image_size=128, is_train=True):\n        self.df = df.reset_index(drop=True).copy()\n        self.img_dir = Path(img_dir)\n        self.is_train = is_train\n        size = image_size\n\n        self.train_tfms = transforms.Compose([\n            transforms.RandomHorizontalFlip(),\n            transforms.RandomVerticalFlip(),\n            transforms.RandomRotation(15),\n            transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.02),\n            transforms.Resize((size, size)),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.25,0.25,0.25]),\n        ])\n        self.valid_tfms = transforms.Compose([\n            transforms.Resize((size, size)),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.25,0.25,0.25]),\n        ])\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img_id = row[\"id\"]\n        path = self.img_dir / f\"{img_id}.tif\"\n        with Image.open(path) as im:\n            im = im.convert(\"RGB\")\n            if self.is_train:\n                im = self.train_tfms(im)\n            else:\n                im = self.valid_tfms(im)\n\n        if \"label\" in row:\n            y = torch.tensor(row[\"label\"], dtype=torch.float32)\n            return im, y\n        else:\n            return im, img_id\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T18:02:36.938219Z","iopub.execute_input":"2025-10-22T18:02:36.938469Z","iopub.status.idle":"2025-10-22T18:02:36.948147Z","shell.execute_reply.started":"2025-10-22T18:02:36.938453Z","shell.execute_reply":"2025-10-22T18:02:36.947370Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndef build_model(model_name=\"resnet18\"):\n    if model_name == \"resnet18\":\n        model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n        # Replace the final layer for binary classification\n        in_features = model.fc.in_features\n        model.fc = nn.Linear(in_features, 1)\n    else:\n        raise ValueError(\"Unsupported model_name\")\n    return model\n\ndef get_class_weights(labels):\n    # Compute positive and negative weights for BCEWithLogitsLoss pos_weight\n    pos = labels.sum()\n    neg = len(labels) - pos\n    if pos == 0:\n        return torch.tensor([1.0])\n    pos_weight = torch.tensor([neg / max(pos, 1.0)])\n    return pos_weight\n\ndef train_one_epoch(model, loader, criterion, optimizer, scaler=None):\n    model.train()\n    running_loss = 0.0\n    for imgs, targets in loader:\n        imgs = imgs.to(DEVICE)\n        targets = targets.view(-1, 1).to(DEVICE)\n\n        optimizer.zero_grad(set_to_none=True)\n        if scaler is not None:\n            with torch.autocast(device_type=DEVICE if DEVICE != \"cpu\" else \"cpu\", dtype=torch.float16, enabled=True):\n                logits = model(imgs)\n                loss = criterion(logits, targets)\n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n        else:\n            logits = model(imgs)\n            loss = criterion(logits, targets)\n            loss.backward()\n            optimizer.step()\n\n        running_loss += loss.item() * imgs.size(0)\n    return running_loss / len(loader.dataset)\n\n@torch.no_grad()\ndef validate(model, loader, criterion):\n    model.eval()\n    running_loss = 0.0\n    probs_list = []\n    targets_list = []\n    for imgs, targets in loader:\n        imgs = imgs.to(DEVICE)\n        targets = targets.view(-1, 1).to(DEVICE)\n        logits = model(imgs)\n        loss = criterion(logits, targets)\n        running_loss += loss.item() * imgs.size(0)\n        probs = torch.sigmoid(logits).detach().cpu().numpy().ravel().tolist()\n        probs_list.extend(probs)\n        targets_list.extend(targets.detach().cpu().numpy().ravel().tolist())\n\n    avg_loss = running_loss / len(loader.dataset)\n    try:\n        auc = roc_auc_score(targets_list, probs_list)\n    except Exception:\n        auc = float(\"nan\")\n    return avg_loss, auc, np.array(probs_list), np.array(targets_list)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T18:02:36.948785Z","iopub.execute_input":"2025-10-22T18:02:36.949027Z","iopub.status.idle":"2025-10-22T18:02:36.961960Z","shell.execute_reply.started":"2025-10-22T18:02:36.949006Z","shell.execute_reply":"2025-10-22T18:02:36.961257Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nassert LABELS_CSV.exists(), \"train_labels.csv not found. Please set DATA_DIR correctly.\"\nlabels_df = pd.read_csv(LABELS_CSV)\nprint(labels_df.head(), labels_df.shape, labels_df.label.mean())\nskf = StratifiedKFold(n_splits=CFG.folds, shuffle=True, random_state=SEED)\n\nfolds = []\nfor f, (_, val_idx) in enumerate(skf.split(labels_df[\"id\"], labels_df[\"label\"])):\n    fold = labels_df.copy()\n    fold[\"fold\"] = -1\n    fold.loc[val_idx, \"fold\"] = f\n    folds.append(fold)\n\n# Use one fold for a quick baseline\ndf = folds[CFG.train_fold]\ntrain_df = df[df.fold != CFG.train_fold].drop(columns=[\"fold\"])\nvalid_df = df[df.fold == CFG.train_fold].drop(columns=[\"fold\"])\n\nprint(\"Train size:\", len(train_df), \"Valid size:\", len(valid_df))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T18:02:36.962553Z","iopub.execute_input":"2025-10-22T18:02:36.962853Z","iopub.status.idle":"2025-10-22T18:02:37.412268Z","shell.execute_reply.started":"2025-10-22T18:02:36.962805Z","shell.execute_reply":"2025-10-22T18:02:37.411518Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ntrain_ds = HistoDataset(train_df, TRAIN_DIR, image_size=CFG.image_size, is_train=True)\nvalid_ds = HistoDataset(valid_df, TRAIN_DIR, image_size=CFG.image_size, is_train=False)\n\n# Weighted sampling to reduce class imbalance\nlabels_np = train_df[\"label\"].values\nclass_sample_count = np.array([len(np.where(labels_np == t)[0]) for t in [0,1]])\nweights = 1. / class_sample_count\nsamples_weight = np.array([weights[t] for t in labels_np])\nsamples_weight = torch.from_numpy(samples_weight).float()\nsampler = WeightedRandomSampler(samples_weight, num_samples=len(samples_weight), replacement=True)\n\ntrain_loader = DataLoader(train_ds, batch_size=CFG.batch_size, sampler=sampler,\n                          num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\nvalid_loader = DataLoader(valid_ds, batch_size=CFG.batch_size, shuffle=False,\n                          num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T18:02:37.413057Z","iopub.execute_input":"2025-10-22T18:02:37.413298Z","iopub.status.idle":"2025-10-22T18:02:37.473470Z","shell.execute_reply.started":"2025-10-22T18:02:37.413279Z","shell.execute_reply":"2025-10-22T18:02:37.472860Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2. EDA: inspect, visualize, clean, plan (15 pts)","metadata":{}},{"cell_type":"code","source":"# EDA: integrity checks, class balance, sample tiles, plan of analysis\n\nimport numpy as np, pandas as pd, matplotlib.pyplot as plt\nfrom PIL import Image\nfrom pathlib import Path\n\nassert 'labels_df' in globals(), \"Expected labels_df to be loaded from train_labels.csv\"\nassert 'TRAIN_DIR' in globals(), \"Expected TRAIN_DIR to point to the training images\"\n\n# Basic checks\nmissing_ids = labels_df['id'].isna().sum()\nmissing_labels = labels_df['label'].isna().sum()\ndup_ids = labels_df['id'].duplicated().sum()\nprint({'missing_id_rows': int(missing_ids),\n       'missing_label_rows': int(missing_labels),\n       'duplicate_id_rows': int(dup_ids)})\n\n# Drop obvious bad rows if any\nclean_df = labels_df.dropna(subset=['id','label']).drop_duplicates(subset=['id']).copy()\nprint('Kept rows after cleaning:', len(clean_df))\n\n# Class distribution\ncls_counts = clean_df['label'].value_counts().sort_index()\ncls_ratio = cls_counts / cls_counts.sum()\ndisplay(pd.DataFrame({'count': cls_counts, 'ratio': cls_ratio}))\n\n# Histogram of labels\nax = cls_counts.plot(kind='bar', figsize=(4,3), title='Label distribution (0=normal, 1=tumor)')\nax.set_xlabel('Label'); ax.set_ylabel('Count'); plt.show()\n\n# Utility to show example tiles\ndef show_examples(df, cls=0, n=9, img_dir=TRAIN_DIR, seed=42):\n    subset = df[df.label == cls]\n    n = min(n, len(subset))\n    ids = subset['id'].sample(n, random_state=seed).tolist()\n    cols = 3\n    rows = int(np.ceil(n/cols))\n    plt.figure(figsize=(3*cols, 3*rows))\n    for i, id_ in enumerate(ids, 1):\n        path = Path(img_dir) / f\"{id_}.tif\"\n        with Image.open(path) as im:\n            im = im.convert(\"RGB\")\n            plt.subplot(rows, cols, i)\n            plt.imshow(im)\n            plt.axis('off')\n            plt.title(f\"label={cls}\")\n    plt.tight_layout(); plt.show()\n\nprint(\"Example normal tiles\")\nshow_examples(clean_df, cls=0, n=9)\nprint(\"Example tumor tiles\")\nshow_examples(clean_df, cls=1, n=9)\n\n# Plan of analysis derived from EDA\nprint(\"\"\"\nPlan of analysis:\n1) Use transfer learning with standard CNN backbones (ResNet18, ResNet34, optionally EfficientNet-B0).\n2) Address class imbalance using WeightedRandomSampler and BCEWithLogitsLoss(pos_weight).\n3) Apply light augmentations (flip, rotate, color jitter). Normalize images.\n4) Stratified K-Fold; for speed, train one fold and report metrics. Optionally extend to all folds later.\n5) Small hyperparameter grid over lr and weight decay. Pick best on validation AUC.\n6) Produce results tables, plots, and a short conclusion.\n\"\"\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model architecture and rationale\n\nI compare residual convolutional backbones that are strong and efficient on small tiles:\n- ResNet18 and ResNet34: good tradeoff between capacity and speed\n- Optional EfficientNet-B0: parameter efficient baseline\n\nI replace the final classification layer with a single logit for binary classification and use `BCEWithLogitsLoss`. Class imbalance is handled both via a `pos_weight` in the loss and a `WeightedRandomSampler`. Mixed precision is used when GPU is available.\n","metadata":{}},{"cell_type":"code","source":"\nmodel = build_model(CFG.model_name).to(DEVICE)\n\n# Loss\npos_weight = get_class_weights(train_df[\"label\"].values).to(DEVICE)\ncriterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n\noptimizer = optim.AdamW(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\nscheduler = CosineAnnealingLR(optimizer, T_max=CFG.t_max)\n\nscaler = torch.cuda.amp.GradScaler(enabled=CFG.mixed_precision and DEVICE == \"cuda\")\n\nbest_auc = -1.0\nbest_path = os.path.join(CFG.save_dir, f\"{CFG.model_name}_fold{CFG.train_fold}.pt\")\nno_improve = 0\n\nfor epoch in range(1, CFG.epochs + 1):\n    t0 = time.time()\n    train_loss = train_one_epoch(model, train_loader, criterion, optimizer, scaler=scaler)\n    val_loss, val_auc, _, _ = validate(model, valid_loader, criterion)\n    scheduler.step()\n    dt = time.time() - t0\n    print(f\"Epoch {epoch:02d} | {dt:.1f}s | train_loss {train_loss:.4f} | val_loss {val_loss:.4f} | val_auc {val_auc:.4f}\")\n\n    if val_auc > best_auc:\n        best_auc = val_auc\n        torch.save({\"model\": model.state_dict(), \"cfg\": asdict(CFG)}, best_path)\n        no_improve = 0\n        print(\"Saved new best model to\", best_path)\n    else:\n        no_improve += 1\n        if no_improve >= CFG.patience:\n            print(\"Early stopping triggered\")\n            break\n\nprint(\"Best AUC:\", best_auc)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T18:02:37.474224Z","iopub.execute_input":"2025-10-22T18:02:37.474532Z","iopub.status.idle":"2025-10-22T18:27:39.925147Z","shell.execute_reply.started":"2025-10-22T18:02:37.474509Z","shell.execute_reply":"2025-10-22T18:27:39.924181Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Build test loader\nassert TEST_DIR.exists(), \"test directory not found\"\ntest_ids = [p.stem for p in sorted(TEST_DIR.glob(\"*.tif\"))]\ntest_df = pd.DataFrame({\"id\": test_ids})\n\ntest_ds = HistoDataset(test_df, TEST_DIR, image_size=CFG.image_size, is_train=False)\ntest_loader = DataLoader(test_ds, batch_size=CFG.batch_size, shuffle=False,\n                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n\n# Load best checkpoint\nckpt = torch.load(best_path, map_location=DEVICE)\nmodel = build_model(CFG.model_name).to(DEVICE)\nmodel.load_state_dict(ckpt[\"model\"])\nmodel.eval()\n\nprobs = []\nwith torch.no_grad():\n    for imgs, ids in test_loader:\n        imgs = imgs.to(DEVICE)\n        logits = model(imgs)\n        p = torch.sigmoid(logits).detach().cpu().numpy().ravel()\n        probs.extend(p.tolist())\n\nsubmission = pd.DataFrame({\"id\": test_df[\"id\"], \"label\": np.array(probs)})\nsubmission_path = \"submission.csv\"\nsubmission.to_csv(submission_path, index=False)\nprint(\"Wrote\", submission_path, \"with\", len(submission), \"rows\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T18:27:39.926396Z","iopub.execute_input":"2025-10-22T18:27:39.927014Z","iopub.status.idle":"2025-10-22T18:32:30.006358Z","shell.execute_reply.started":"2025-10-22T18:27:39.926989Z","shell.execute_reply":"2025-10-22T18:32:30.005227Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Sanity check on validation predictions and optimal threshold\nval_loss, val_auc, val_probs, val_targets = validate(model, valid_loader, criterion)\nprint(\"Validation AUC with reloaded model:\", val_auc)\n\n# Find a threshold that maximizes F1 on the validation set\nbest_thr, best_f1 = 0.5, -1\nfor thr in np.linspace(0.1, 0.9, 17):\n    preds = (val_probs >= thr).astype(int)\n    tp = ((preds == 1) & (val_targets == 1)).sum()\n    fp = ((preds == 1) & (val_targets == 0)).sum()\n    fn = ((preds == 0) & (val_targets == 1)).sum()\n    precision = tp / max(tp + fp, 1)\n    recall = tp / max(tp + fn, 1)\n    f1 = 2 * precision * recall / max(precision + recall, 1e-9)\n    if f1 > best_f1:\n        best_f1, best_thr = f1, thr\nprint(f\"Best F1 {best_f1:.4f} at thr {best_thr:.2f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T18:32:30.008968Z","iopub.execute_input":"2025-10-22T18:32:30.009210Z","iopub.status.idle":"2025-10-22T18:33:19.286928Z","shell.execute_reply.started":"2025-10-22T18:32:30.009190Z","shell.execute_reply":"2025-10-22T18:33:19.285948Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 4) Stratified split, loaders, and small hyperparameter search across architectures (addresses Model Architecture 25 pts and Results 35 pts)","metadata":{}},{"cell_type":"code","source":"# Config for this section\nfrom dataclasses import dataclass, asdict\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nfrom sklearn.model_selection import StratifiedKFold\n\n@dataclass\nclass SearchConfig:\n    image_size: int = 128\n    batch_size: int = 256\n    epochs: int = 5\n    folds: int = 5\n    train_fold: int = 0\n    patience: int = 2\n    lr_grid: tuple = (3e-4, 1e-4)\n    wd_grid: tuple = (1e-4, 3e-5)\n    archs: tuple = (\"resnet18\", \"resnet34\")\n    num_workers: int = 2\n    mixed_precision: bool = True\n    save_dir: str = \"./checkpoints_search\"\n\nSCFG = SearchConfig()\nos.makedirs(SCFG.save_dir, exist_ok=True)\n\n# Stratified split\nskf = StratifiedKFold(n_splits=SCFG.folds, shuffle=True, random_state=42)\nfolds = []\nfor f, (_, val_idx) in enumerate(skf.split(labels_df['id'], labels_df['label'])):\n    fold = labels_df.copy()\n    fold['fold'] = -1\n    fold.loc[val_idx, 'fold'] = f\n    folds.append(fold)\n\ndf = folds[SCFG.train_fold]\ntrain_df = df[df.fold != SCFG.train_fold].drop(columns=['fold'])\nvalid_df = df[df.fold == SCFG.train_fold].drop(columns=['fold'])\n\n# Datasets and loaders with weighted sampler\ntrain_ds = HistoDataset(train_df, TRAIN_DIR, image_size=SCFG.image_size, is_train=True)\nvalid_ds = HistoDataset(valid_df, TRAIN_DIR, image_size=SCFG.image_size, is_train=False)\n\nlabels_np = train_df['label'].values\nclass_sample_count = np.array([(labels_np == 0).sum(), (labels_np == 1).sum()])\nweights = 1.0 / class_sample_count\nsamples_weight = np.array([weights[t] for t in labels_np])\nsamples_weight = torch.from_numpy(samples_weight).float()\nsampler = WeightedRandomSampler(samples_weight, num_samples=len(samples_weight), replacement=True)\n\ndef make_loaders(bs):\n    train_loader = DataLoader(train_ds, batch_size=bs, sampler=sampler,\n                              num_workers=SCFG.num_workers, pin_memory=True, drop_last=False)\n    valid_loader = DataLoader(valid_ds, batch_size=bs, shuffle=False,\n                              num_workers=SCFG.num_workers, pin_memory=True, drop_last=False)\n    return train_loader, valid_loader\n\ndef get_pos_weight(labels):\n    pos = labels.sum()\n    neg = len(labels) - pos\n    return torch.tensor([neg / max(pos, 1.0)], device=DEVICE)\n\n# Tiny search over architectures and hyperparameters\nfrom itertools import product\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nresults = []\n\nfor arch, lr, wd in product(SCFG.archs, SCFG.lr_grid, SCFG.wd_grid):\n    print(f\"Search run: arch={arch} lr={lr} wd={wd}\")\n    train_loader, valid_loader = make_loaders(SCFG.batch_size)\n    model = build_model(arch).to(DEVICE)\n    criterion = nn.BCEWithLogitsLoss(pos_weight=get_pos_weight(train_df['label'].values))\n    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n    scheduler = CosineAnnealingLR(optimizer, T_max=max(SCFG.epochs, 1))\n    scaler = torch.cuda.amp.GradScaler(enabled=SCFG.mixed_precision and DEVICE==\"cuda\")\n\n    best_auc, best_state = -1.0, None\n    no_improve = 0\n    history = []\n\n    for epoch in range(1, SCFG.epochs + 1):\n        tr_loss = train_one_epoch(model, train_loader, criterion, optimizer, scaler=scaler)\n        val_loss, val_auc, _, _ = validate(model, valid_loader, criterion)\n        scheduler.step()\n        history.append({'epoch': epoch, 'train_loss': tr_loss, 'val_loss': val_loss, 'val_auc': val_auc})\n        print(f\"Epoch {epoch:02d} train_loss={tr_loss:.4f} val_loss={val_loss:.4f} val_auc={val_auc:.4f}\")\n        if val_auc > best_auc:\n            best_auc, best_state = val_auc, model.state_dict()\n            no_improve = 0\n        else:\n            no_improve += 1\n            if no_improve >= SCFG.patience:\n                print(\"Early stopping\")\n                break\n\n    results.append({'arch': arch, 'lr': lr, 'weight_decay': wd,\n                    'best_val_auc': best_auc, 'history': history})\n\nresults_df = pd.DataFrame([{k:v for k,v in r.items() if k != 'history'} for r in results]).sort_values('best_val_auc', ascending=False)\ndisplay(results_df)\n\n# Plot best AUC per architecture\narch_best = results_df.groupby('arch')['best_val_auc'].max().sort_values(ascending=False)\nax = arch_best.plot(kind='bar', figsize=(5,3), title='Best validation AUC by architecture')\nax.set_xlabel('Architecture'); ax.set_ylabel('Best AUC'); plt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Conclusion and discussion\n\nSummary\n- Best model and validation AUC\n- Which augmentations and hyperparameters helped\n- Common failure modes observed from tiles\n\nWhat did not help\n- Briefly note any changes that did not improve AUC or stability\n\nNext steps\n- Train all folds and average probabilities\n- Try larger image sizes or stain normalization\n- Test-time augmentation and calibration\n- Explore larger backbones or self-supervised encoders\n","metadata":{}}]}